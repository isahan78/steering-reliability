{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Steering Reliability - Iterative Experiments (Colab)\n\nThis notebook uses a **progressive iteration strategy** instead of one long experiment.\n\n**Iteration Ladder:**\n1. **Smoke Test** (5 min) - Verify pipeline works\n2. **Layer Comparison** (15 min) - Find best layer  \n3. **Alpha Sweep** (30 min) - Tune steering strength\n4. **Full Experiment** (1-2 hours) - Publication results\n\n**Benefits:**\n- ✅ Fast feedback loops\n- ✅ Learn from each iteration\n- ✅ Lower risk of Colab disconnects\n- ✅ More efficient compute usage\n\n---\n\n## Setup Instructions\n\n1. **Enable GPU:** Runtime → Change runtime type → GPU (T4 or A100)\n2. **Run setup cells** (1-3)\n3. **Run experiments progressively** (start with smoke test)\n4. **Download results after each level**\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository from GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your repository (replace with your GitHub URL)\n",
    "# If public repo:\n",
    "!git clone https://github.com/isahan78/steering-reliability.git\n",
    "\n",
    "# If private repo, you'll be prompted for credentials\n",
    "# Or use: !git clone https://YOUR_TOKEN@github.com/YOUR_USERNAME/steering-reliability.git\n",
    "\n",
    "%cd steering-reliability\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# IMPORTANT: Using virtual environment to avoid numpy version conflicts\n# This is necessary because Colab has pre-installed packages that require numpy>=2\n# but TransformerLens requires numpy<2 for Python 3.12\n\n# Install virtualenv\n!pip install -q virtualenv\n\n# Create virtual environment\n!virtualenv -p python3 venv\n\nimport sys\nsys.path.insert(0, '/content/steering-reliability/venv/lib/python3.10/site-packages')\n\n# Install dependencies in isolated environment\n!/content/steering-reliability/venv/bin/pip install -q torch transformer-lens transformers datasets pandas 'numpy<2.0' matplotlib seaborn pyyaml tqdm pyarrow scikit-learn\n\n# Add src to Python path\nsys.path.insert(0, '/content/steering-reliability/src')\n\n# Verify GPU availability\nimport torch\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
  },
  {
   "cell_type": "code",
   "source": "# Verify imports work (CRITICAL TEST)\nimport sys\nsys.path.insert(0, '/content/steering-reliability/venv/lib/python3.10/site-packages')\nsys.path.insert(0, '/content/steering-reliability/src')\n\nprint(\"=\"*60)\nprint(\"IMPORT VERIFICATION TEST\")\nprint(\"=\"*60)\n\ntry:\n    import numpy as np\n    print(f\"✓ numpy {np.__version__}\")\n    \n    from steering_reliability.config import load_config\n    print(\"✓ config module\")\n    \n    from steering_reliability.model import load_model\n    print(\"✓ model module\")\n    \n    from steering_reliability.data import load_prompts\n    print(\"✓ data module\")\n    \n    import transformer_lens\n    print(f\"✓ transformer_lens {transformer_lens.__version__}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"✅ SUCCESS! All imports work correctly.\")\n    print(\"=\"*60)\n    print(\"\\nYou can now proceed with the experiment.\")\n    \nexcept Exception as e:\n    print(\"\\n\" + \"=\"*60)\n    print(\"❌ IMPORT FAILED!\")\n    print(\"=\"*60)\n    print(f\"Error: {e}\")\n    print(\"\\nPlease report this error.\")\n    import traceback\n    traceback.print_exc()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Data and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check prompt datasets exist\n",
    "!ls -lh data/prompts/\n",
    "\n",
    "# Show configuration\n",
    "!cat configs/default.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. (Optional) Mount Google Drive\n",
    "\n",
    "Mount Drive to automatically save results. Skip if you prefer manual download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 5. Run Experiments (Iteratively)\n\n**Start with Level 1, then progress upward based on results!**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# LEVEL 1: Smoke Test (5 minutes)\n# Verify pipeline works end-to-end\n!python scripts/run_all.py --config configs/smoke.yaml"
  },
  {
   "cell_type": "code",
   "source": "# LEVEL 4: Full Experiment (1-2 hours)\n# Complete sweep for publication results\n# Run this AFTER analyzing results from Levels 1-3\n!python scripts/run_all.py --config configs/full.yaml",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# LEVEL 3: Alpha Sweep (30 minutes)\n# Fine-tune steering strength on best layer\n# IMPORTANT: Edit configs/alpha_sweep.yaml first - set layers to best layer from Level 2\n!python scripts/run_all.py --config configs/alpha_sweep.yaml",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# LEVEL 2: Layer Comparison (15 minutes)\n# Find which layer provides best steering\n!python scripts/run_all.py --config configs/layer_test.yaml",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the full pipeline\n",
    "!python scripts/run_all.py --config configs/default.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List generated files\n",
    "!ls -lhR artifacts/runs/full_gpt2_medium/\n",
    "\n",
    "# Show summary table\n",
    "!head -20 artifacts/tables/summary.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. View Plots Inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "plot_dir = \"artifacts/figures\"\n",
    "plots = [\n",
    "    \"generalization_gap.png\",\n",
    "    \"tradeoff_curve.png\",\n",
    "    \"heatmap_refusal_harm_test.png\",\n",
    "    \"heatmap_helpfulness_benign.png\"\n",
    "]\n",
    "\n",
    "for plot in plots:\n",
    "    path = os.path.join(plot_dir, plot)\n",
    "    if os.path.exists(path):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  {plot}\")\n",
    "        print('='*60)\n",
    "        display(Image(filename=path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Results\n",
    "\n",
    "### Option A: Download as ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ZIP of all results\n",
    "!zip -r steering_reliability_results.zip artifacts/ -x \"*.git/*\"\n",
    "\n",
    "# Download the zip file\n",
    "from google.colab import files\n",
    "files.download('steering_reliability_results.zip')\n",
    "\n",
    "print(\"\\n✓ Results ZIP created and download started!\")\n",
    "print(\"  Extract this on your local machine and commit to Git\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Copy to Google Drive (if mounted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you mounted Drive earlier\n",
    "# !cp -r artifacts/ /content/drive/MyDrive/steering_reliability_results/\n",
    "# print(\"✓ Results copied to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick Analysis\n",
    "\n",
    "View key metrics before downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load summary\n",
    "summary = pd.read_csv('artifacts/tables/summary.csv')\n",
    "\n",
    "# Show baseline vs best steering config\n",
    "print(\"=\" * 80)\n",
    "print(\"BASELINE RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "baseline = summary[summary['intervention_type'] == 'none']\n",
    "print(baseline[['split', 'is_refusal_mean', 'is_helpful_mean']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BEST CONFIGS BY LAYER (Highest refusal on harm_test, lowest side effects)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find best configs per layer\n",
    "harm_test = summary[\n",
    "    (summary['split'] == 'harm_test') & \n",
    "    (summary['intervention_type'] != 'none')\n",
    "].sort_values('is_refusal_mean', ascending=False)\n",
    "\n",
    "print(harm_test[[\n",
    "    'layer', 'alpha', 'intervention_type', \n",
    "    'is_refusal_mean', 'is_helpful_mean'\n",
    "]].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Download** the results ZIP\n",
    "2. **Extract** on your local machine in the repo\n",
    "3. **Commit** to Git:\n",
    "   ```bash\n",
    "   git add artifacts/\n",
    "   git commit -m \"Full experiment results: gpt2-medium\"\n",
    "   git push\n",
    "   ```\n",
    "4. **Analyze** the plots and data locally\n",
    "5. **Iterate** - adjust config and rerun on Colab as needed\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}