{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steering Reliability - Fast Iteration Experiments\n",
    "\n",
    "Progressive experimentation using **GPT-2 Small** for fast iteration.\n",
    "\n",
    "**Timeline:**\n",
    "- Level 1: Smoke Test (2-3 min)\n",
    "- Level 2: Layer Comparison (10-12 min)\n",
    "- Level 3: Alpha Sweep (20-25 min)\n",
    "- Level 4: Full Sweep (30-40 min)\n",
    "\n",
    "**Total:** ~1 hour with analysis time\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Enable GPU:** Runtime ‚Üí Change runtime type ‚Üí GPU (T4 or A100)\n",
    "2. **Run setup cells** (Cells 1-3) in order\n",
    "3. **Run experiments progressively** (Cells 4-7)\n",
    "4. **Analyze after each level** (included in each section)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/isahan78/steering-reliability.git\n",
    "%cd steering-reliability\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies\n",
    "\n",
    "This installs all packages with compatible versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uninstall any conflicting packages\n",
    "!pip uninstall -y numpy pandas datasets transformer-lens transformers pyarrow scikit-learn -q\n",
    "\n",
    "# Install all dependencies in one command (ensures compatibility)\n",
    "!pip install --no-cache-dir numpy pandas torch transformer-lens transformers datasets matplotlib seaborn pyyaml tqdm pyarrow scikit-learn\n",
    "\n",
    "# Add src to Python path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/steering-reliability/src')\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Verify Setup\n",
    "\n",
    "**IMPORTANT:** This cell must show \"‚úÖ SUCCESS\" before proceeding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/steering-reliability/src')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"IMPORT VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"‚úì numpy {np.__version__}\")\n",
    "    \n",
    "    from transformer_lens import HookedTransformer\n",
    "    print(f\"‚úì transformer_lens.HookedTransformer\")\n",
    "    \n",
    "    from steering_reliability.config import load_config\n",
    "    print(\"‚úì config module\")\n",
    "    \n",
    "    from steering_reliability.model import load_model\n",
    "    print(\"‚úì model module\")\n",
    "    \n",
    "    from steering_reliability.data import load_prompts\n",
    "    print(\"‚úì data module\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ SUCCESS! All imports work.\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nReady to run experiments!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚ùå FAILED!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nPlease report this error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Experiments\n",
    "\n",
    "Run these **one at a time**, analyzing results after each level.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1: Smoke Test (2-3 minutes)\n",
    "\n",
    "**Goal:** Verify pipeline works end-to-end\n",
    "\n",
    "**Config:**\n",
    "- Model: GPT-2 Small (124M params)\n",
    "- Prompts: 20 per split\n",
    "- Layers: 6, 10\n",
    "- Alphas: 0, 2, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_all.py --config configs/gpt2_small_smoke.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Check: Did it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results were generated\n",
    "!ls -lh artifacts/runs/gpt2_small_smoke/\n",
    "\n",
    "# Show summary stats\n",
    "import pandas as pd\n",
    "summary = pd.read_csv('artifacts/tables/summary.csv')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SMOKE TEST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(summary[['split', 'layer', 'alpha', 'intervention_type', 'is_refusal_mean', 'is_helpful_mean']].to_string(index=False))\n",
    "\n",
    "print(\"\\n‚úÖ If you see results above, smoke test passed!\")\n",
    "print(\"   Ready to proceed to Level 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Smoke Test Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r smoke_test_results.zip artifacts/\n",
    "from google.colab import files\n",
    "files.download('smoke_test_results.zip')\n",
    "print(\"\\n‚úì Results downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Level 2: Layer Comparison (10-12 minutes)\n",
    "\n",
    "**Goal:** Find which layer provides best steering effect\n",
    "\n",
    "**Config:**\n",
    "- Prompts: 50 per split\n",
    "- Layers: 4, 6, 8, 10 (early ‚Üí late)\n",
    "- Alphas: 0, 2, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_all.py --config configs/gpt2_small_layer_test.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Which Layer is Best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary = pd.read_csv('artifacts/tables/summary.csv')\n",
    "\n",
    "# Filter to harm_test with alpha=4 (strong steering)\n",
    "harm_test = summary[\n",
    "    (summary['split'] == 'harm_test') &\n",
    "    (summary['alpha'] == 4)\n",
    "].sort_values('is_refusal_mean', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LAYER COMPARISON RESULTS (harm_test, alpha=4)\")\n",
    "print(\"=\"*80)\n",
    "print(harm_test[['layer', 'is_refusal_mean', 'is_helpful_mean']].to_string(index=False))\n",
    "\n",
    "best_layer = harm_test.iloc[0]['layer']\n",
    "print(f\"\\nüéØ BEST LAYER: {int(best_layer)}\")\n",
    "print(f\"   Refusal rate: {harm_test.iloc[0]['is_refusal_mean']:.2f}\")\n",
    "print(f\"\\nüí° Use this layer in Level 3 (alpha sweep)\")\n",
    "\n",
    "# Plot layer comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "for layer in [4, 6, 8, 10]:\n",
    "    layer_data = summary[\n",
    "        (summary['split'] == 'harm_test') &\n",
    "        (summary['layer'] == layer)\n",
    "    ].sort_values('alpha')\n",
    "    plt.plot(layer_data['alpha'], layer_data['is_refusal_mean'], marker='o', label=f'Layer {int(layer)}')\n",
    "\n",
    "plt.xlabel('Alpha (Steering Strength)')\n",
    "plt.ylabel('Refusal Rate (harm_test)')\n",
    "plt.title('Layer Comparison: Refusal Rate vs Alpha')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Layer Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r layer_test_results.zip artifacts/\n",
    "from google.colab import files\n",
    "files.download('layer_test_results.zip')\n",
    "print(\"\\n‚úì Results downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Level 3: Alpha Sweep (20-25 minutes)\n",
    "\n",
    "**IMPORTANT:** Before running this, update the config with your best layer from Level 2!\n",
    "\n",
    "**Goal:** Fine-tune steering strength\n",
    "\n",
    "**Config:**\n",
    "- Prompts: 100 per split\n",
    "- Layers: [BEST_LAYER] (update below)\n",
    "- Alphas: 0, 1, 2, 4, 8\n",
    "- Interventions: add, ablate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THIS: Replace 6 with your best layer from Level 2\n",
    "BEST_LAYER = 6  # <-- CHANGE THIS\n",
    "\n",
    "# Update the config file\n",
    "import yaml\n",
    "\n",
    "with open('configs/gpt2_small_alpha_sweep.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['experiment']['layers'] = [BEST_LAYER]\n",
    "\n",
    "with open('configs/gpt2_small_alpha_sweep.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(f\"‚úì Updated config to use layer {BEST_LAYER}\")\n",
    "print(\"\\nRunning alpha sweep...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_all.py --config configs/gpt2_small_alpha_sweep.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis: Optimal Alpha and Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "summary = pd.read_csv('artifacts/tables/summary.csv')\n",
    "\n",
    "# Get harm_test and benign data\n",
    "harm_test = summary[summary['split'] == 'harm_test']\n",
    "benign = summary[summary['split'] == 'benign']\n",
    "\n",
    "# Merge for tradeoff analysis\n",
    "merged = harm_test.merge(\n",
    "    benign,\n",
    "    on=['layer', 'alpha', 'intervention_type'],\n",
    "    suffixes=('_harm', '_benign')\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ALPHA SWEEP RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(merged[[\n",
    "    'alpha', 'intervention_type',\n",
    "    'is_refusal_mean_harm', 'is_helpful_mean_benign'\n",
    "]].to_string(index=False))\n",
    "\n",
    "# Find best config (high refusal, low side effects)\n",
    "best = merged.sort_values(\n",
    "    ['is_refusal_mean_harm', 'is_helpful_mean_benign'],\n",
    "    ascending=[False, False]\n",
    ").iloc[0]\n",
    "\n",
    "print(f\"\\nüéØ BEST CONFIG:\")\n",
    "print(f\"   Layer: {int(best['layer'])}\")\n",
    "print(f\"   Alpha: {best['alpha']}\")\n",
    "print(f\"   Intervention: {best['intervention_type']}\")\n",
    "print(f\"   Refusal rate: {best['is_refusal_mean_harm']:.2f}\")\n",
    "print(f\"   Helpfulness (benign): {best['is_helpful_mean_benign']:.2f}\")\n",
    "\n",
    "# Plot tradeoff curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "for intervention in ['add', 'ablate']:\n",
    "    data = merged[merged['intervention_type'] == intervention]\n",
    "    plt.scatter(\n",
    "        1 - data['is_helpful_mean_benign'],\n",
    "        data['is_refusal_mean_harm'],\n",
    "        label=intervention.capitalize(),\n",
    "        s=100,\n",
    "        alpha=0.6\n",
    "    )\n",
    "    for _, row in data.iterrows():\n",
    "        plt.annotate(\n",
    "            f\"Œ±={row['alpha']}\",\n",
    "            (1 - row['is_helpful_mean_benign'], row['is_refusal_mean_harm']),\n",
    "            fontsize=8\n",
    "        )\n",
    "\n",
    "plt.xlabel('Helpfulness Drop (Benign)')\n",
    "plt.ylabel('Refusal Rate (Harmful)')\n",
    "plt.title('Tradeoff Curve: Refusal vs Side Effects')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Alpha Sweep Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r alpha_sweep_results.zip artifacts/\n",
    "from google.colab import files\n",
    "files.download('alpha_sweep_results.zip')\n",
    "print(\"\\n‚úì Results downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Level 4: Full Sweep (30-40 minutes)\n",
    "\n",
    "**Goal:** Complete development results with full dataset\n",
    "\n",
    "**Config:**\n",
    "- Prompts: All (150/150/200)\n",
    "- Layers: 4, 6, 8, 10\n",
    "- Alphas: 0, 1, 2, 4, 8\n",
    "- Interventions: add, ablate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/run_all.py --config configs/gpt2_small_full.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Final Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "plot_dir = \"artifacts/figures\"\n",
    "plots = [\n",
    "    \"generalization_gap.png\",\n",
    "    \"tradeoff_curve.png\",\n",
    "    \"heatmap_refusal_harm_test.png\",\n",
    "    \"heatmap_helpfulness_benign.png\"\n",
    "]\n",
    "\n",
    "for plot in plots:\n",
    "    path = os.path.join(plot_dir, plot)\n",
    "    if os.path.exists(path):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"  {plot}\")\n",
    "        print('='*60)\n",
    "        display(Image(filename=path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary = pd.read_csv('artifacts/tables/summary.csv')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BASELINE RESULTS (No Intervention)\")\n",
    "print(\"=\"*80)\n",
    "baseline = summary[summary['intervention_type'] == 'none']\n",
    "print(baseline[['split', 'is_refusal_mean', 'is_helpful_mean']].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 CONFIGS (Highest refusal on harm_test)\")\n",
    "print(\"=\"*80)\n",
    "harm_test = summary[\n",
    "    (summary['split'] == 'harm_test') &\n",
    "    (summary['intervention_type'] != 'none')\n",
    "].sort_values('is_refusal_mean', ascending=False)\n",
    "\n",
    "print(harm_test[[\n",
    "    'layer', 'alpha', 'intervention_type',\n",
    "    'is_refusal_mean', 'is_helpful_mean'\n",
    "]].head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ FULL SWEEP COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Download results (cell below)\")\n",
    "print(\"2. Analyze findings\")\n",
    "print(\"3. Optional: Validate on GPT-2 Medium with best configs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r gpt2_small_full_results.zip artifacts/ -x \"*.git/*\"\n",
    "from google.colab import files\n",
    "files.download('gpt2_small_full_results.zip')\n",
    "\n",
    "print(\"\\n‚úì All results downloaded!\")\n",
    "print(\"\\nExtract this ZIP on your local machine and commit to Git:\")\n",
    "print(\"  git add artifacts/\")\n",
    "print(\"  git commit -m 'GPT-2 Small full experiment results'\")\n",
    "print(\"  git push\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optional: Validate on GPT-2 Medium\n",
    "\n",
    "After finding best configs on GPT-2 Small, validate on larger model.\n",
    "\n",
    "**Layer scaling:** GPT-2 Small (12 layers) ‚Üí Medium (24 layers) = 2x\n",
    "- Small Layer 6 ‚Üí Medium Layer 12\n",
    "- Small Layer 8 ‚Üí Medium Layer 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create targeted medium config\n",
    "# UPDATE these values based on your GPT-2 Small findings\n",
    "\n",
    "BEST_SMALL_LAYER = 6  # <-- Your best layer from small\n",
    "BEST_ALPHA = 4  # <-- Your best alpha\n",
    "BEST_INTERVENTION = \"add\"  # <-- \"add\" or \"ablate\"\n",
    "\n",
    "# Scale layer to medium (2x)\n",
    "MEDIUM_LAYER = BEST_SMALL_LAYER * 2\n",
    "\n",
    "print(f\"Scaling findings to GPT-2 Medium:\")\n",
    "print(f\"  Small Layer {BEST_SMALL_LAYER} ‚Üí Medium Layer {MEDIUM_LAYER}\")\n",
    "print(f\"  Alpha: {BEST_ALPHA}\")\n",
    "print(f\"  Intervention: {BEST_INTERVENTION}\")\n",
    "print(f\"\\nThis targeted run will take ~30 minutes instead of 2 hours!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**What you accomplished:**\n",
    "\n",
    "1. ‚úÖ Verified pipeline works (smoke test)\n",
    "2. ‚úÖ Found best layers for steering\n",
    "3. ‚úÖ Optimized steering strength (alpha)\n",
    "4. ‚úÖ Identified best intervention type\n",
    "5. ‚úÖ Got complete development results\n",
    "\n",
    "**Total time:** ~1 hour with GPT-2 Small vs 3-5 hours with Medium!\n",
    "\n",
    "**Next steps:**\n",
    "- Analyze downloaded results locally\n",
    "- Commit results to Git\n",
    "- Optional: Run targeted validation on GPT-2 Medium\n",
    "- Write up findings\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
