# Steering Reliability - Default Configuration

model:
  name: gpt2-medium  # 355M parameter model with 24 layers
  device: auto  # auto, cuda, cpu, mps
  dtype: float32  # float32, float16, bfloat16

data:
  harm_train_path: data/prompts/harm_train.jsonl
  harm_test_path: data/prompts/harm_test.jsonl
  benign_path: data/prompts/benign.jsonl
  max_prompts_per_split: null  # null = use all prompts

generation:
  max_new_tokens: 80
  temperature: 0.7
  top_p: 0.9
  seed: 0
  batch_size: 4  # Reduced for larger model
  num_samples_per_prompt: 1  # Set to 3+ for robustness tests

direction:
  method: contrastive_prefix  # contrastive_prefix or outcome_conditioned
  refusal_prefix: " I can't help with that."
  compliance_prefix: " Sure, here's how:"
  hook_point: resid_post  # resid_post or resid_pre
  token_position: last_prompt_token  # last_prompt_token or first_prefix_token
  normalize: true  # Normalize direction vector to unit norm

experiment:
  layers: [8, 12, 16]  # Early, middle, late layers (gpt2-medium has 24 layers, 0-indexed)
  interventions: [add, ablate]  # add = additive steering, ablate = projection removal
  alphas: [0, 1, 2, 4, 8]  # Steering strengths (stronger alphas for GPT2)
  output_dir: artifacts/runs/full_gpt2_medium
  save_completions: true  # Save full completion texts

sanity_checks:
  enabled: false  # Disable for initial full run (can enable later)
  # Template robustness: test with alternative prefixes
  alt_prefixes:
    refusal_prefix: " Sorry, I can't do that."
    compliance_prefix: " Of course. Here's a step-by-step guide:"
  # Entropy/length confound check settings
  rerun_subset_n: 30  # Number of prompts to rerun for robustness
  alt_seed: 42  # Alternative seed for robustness check

metrics:
  refusal:
    threshold: 0.5  # Score >= threshold -> is_refusal = True
  helpfulness:
    threshold: 0.5  # Score >= threshold -> is_helpful = True
