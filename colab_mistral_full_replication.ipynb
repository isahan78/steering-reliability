{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral 7B: Complete Experiment Replication\n",
    "\n",
    "This notebook replicates ALL experiments from your paper using Mistral 7B.\n",
    "\n",
    "## Experiments\n",
    "1. **Layer Sensitivity Analysis** (layers 8, 16, 22, 27 | α={0,2,4} | additive)\n",
    "2. **Intervention Comparison** (best layer | α={1,2,4,8} | additive vs ablation)\n",
    "3. **Distribution Shift** (harm_train → harm_test generalization)\n",
    "\n",
    "## Expected Results\n",
    "- Layer sweep: Late layers (27) should perform best\n",
    "- Intervention: Ablation >> Additive\n",
    "- Distribution shift: Minimal generalization gap\n",
    "\n",
    "**Total runtime:** ~3-4 hours on T4, ~2-2.5 hours on A100\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo\n",
    "!git clone https://github.com/isahan78/steering-reliability.git\n",
    "%cd steering-reliability\n",
    "\n",
    "# Install dependencies\n",
    "!pip uninstall -y numpy pandas datasets transformer-lens transformers pyarrow scikit-learn -q\n",
    "!pip install --no-cache-dir numpy pandas torch transformer-lens transformers datasets matplotlib seaborn pyyaml tqdm pyarrow scikit-learn accelerate -q\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/content/steering-reliability/src')\n",
    "\n",
    "import torch\n",
    "print(f\"\\nGPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\" if torch.cuda.is_available() else \"\")\n",
    "\n",
    "print(\"\\n✅ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment 1: Layer Sensitivity Analysis\n",
    "\n",
    "**Goal:** Find which layer best encodes refusal behavior\n",
    "\n",
    "**Setup:**\n",
    "- Layers: 8, 16, 22, 27 (early → late)\n",
    "- Intervention: Additive steering only\n",
    "- Alphas: 0, 2, 4\n",
    "- Splits: harm_train, harm_test, benign (100 prompts each)\n",
    "\n",
    "**Expected:** Layer 27 (late) performs best (~90-95% refusal at α=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = '/content/steering-reliability/src'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT 1: LAYER SENSITIVITY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTesting layers: 8, 16, 22, 27\")\n",
    "print(\"Intervention: Additive steering\")\n",
    "print(\"Alphas: 0, 2, 4\")\n",
    "print(\"\\nExpected runtime: ~60-90 minutes on T4\\n\")\n",
    "\n",
    "!PYTHONPATH=/content/steering-reliability/src python scripts/run_all.py \\\n",
    "  --config configs/mistral_layer_sweep.yaml \\\n",
    "  --skip-baseline\n",
    "\n",
    "print(\"\\n✅ Layer sweep complete!\")\n",
    "print(\"Results: artifacts/runs/mistral_layer_sweep/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Layer Sweep Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load results\n",
    "results_dir = 'artifacts/runs/mistral_layer_sweep'\n",
    "df = pd.read_parquet(f'{results_dir}/all_results.parquet')\n",
    "\n",
    "# Filter to harm_test, additive intervention\n",
    "layer_data = df[\n",
    "    (df['split'] == 'harm_test') & \n",
    "    (df['intervention'] == 'add')\n",
    "]\n",
    "\n",
    "# Compute refusal rates by layer and alpha\n",
    "layer_summary = layer_data.groupby(['layer', 'alpha'])['is_refusal'].mean().reset_index()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LAYER SENSITIVITY RESULTS (harm_test)\")\n",
    "print(\"=\"*80)\n",
    "print(layer_summary.pivot(index='layer', columns='alpha', values='is_refusal'))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for layer in [8, 16, 22, 27]:\n",
    "    layer_df = layer_summary[layer_summary['layer'] == layer]\n",
    "    plt.plot(layer_df['alpha'], layer_df['is_refusal'], marker='o', label=f'Layer {layer}')\n",
    "\n",
    "plt.xlabel('Alpha (Steering Strength)')\n",
    "plt.ylabel('Refusal Rate')\n",
    "plt.title('Layer Sensitivity Analysis - Mistral 7B')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.savefig(f'{results_dir}/layer_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find best layer at alpha=4\n",
    "best_layer = layer_summary[layer_summary['alpha'] == 4].nlargest(1, 'is_refusal')\n",
    "print(f\"\\n✅ Best layer: {int(best_layer['layer'].values[0])} ({best_layer['is_refusal'].values[0]:.1%} refusal at α=4)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Experiment 2: Intervention Mechanism Comparison\n",
    "\n",
    "**Goal:** Compare additive steering vs projection ablation\n",
    "\n",
    "**Setup:**\n",
    "- Layer: Best from sweep (usually 27)\n",
    "- Interventions: Additive AND Ablation\n",
    "- Alphas: 0, 1, 2, 4, 8\n",
    "- Splits: harm_train, harm_test, benign (100 prompts each)\n",
    "\n",
    "**Expected:** Ablation >> Additive (98% vs 83% at α=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import os\n",
    "os.environ['PYTHONPATH'] = '/content/steering-reliability/src'\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT 2: INTERVENTION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nLayer: 27 (best from sweep)\")\n",
    "print(\"Interventions: Additive vs Ablation\")\n",
    "print(\"Alphas: 0, 1, 2, 4, 8\")\n",
    "print(\"\\nExpected runtime: ~60-90 minutes on T4\\n\")\n",
    "\n",
    "!PYTHONPATH=/content/steering-reliability/src python scripts/run_all.py \\\n",
    "  --config configs/mistral_intervention_comparison.yaml \\\n",
    "  --skip-baseline\n",
    "\n",
    "print(\"\\n✅ Intervention comparison complete!\")\n",
    "print(\"Results: artifacts/runs/mistral_intervention_comparison/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Intervention Comparison Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load results\n",
    "results_dir = 'artifacts/runs/mistral_intervention_comparison'\n",
    "df = pd.read_parquet(f'{results_dir}/all_results.parquet')\n",
    "\n",
    "# Compute metrics\n",
    "print(\"=\"*80)\n",
    "print(\"INTERVENTION COMPARISON RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Refusal on harm_test\n",
    "harm_summary = df[df['split'] == 'harm_test'].groupby(['intervention', 'alpha']).agg({\n",
    "    'is_refusal': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nRefusal Rate on harm_test:\")\n",
    "print(harm_summary)\n",
    "\n",
    "# Helpfulness on benign\n",
    "benign_summary = df[df['split'] == 'benign'].groupby(['intervention', 'alpha']).agg({\n",
    "    'is_helpful': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(\"\\nHelpfulness on benign:\")\n",
    "print(benign_summary)\n",
    "\n",
    "# Create comparison table (matching paper format)\n",
    "table_data = []\n",
    "for alpha in [1, 2, 4, 8]:\n",
    "    row = {'alpha': alpha}\n",
    "    \n",
    "    # Additive refusal\n",
    "    add_ref = df[(df['intervention'] == 'add') & (df['alpha'] == alpha) & (df['split'] == 'harm_test')]['is_refusal'].mean()\n",
    "    row['additive_refusal'] = f\"{add_ref:.0%}\"\n",
    "    \n",
    "    # Ablation refusal\n",
    "    abl_ref = df[(df['intervention'] == 'ablate') & (df['alpha'] == alpha) & (df['split'] == 'harm_test')]['is_refusal'].mean()\n",
    "    row['ablation_refusal'] = f\"{abl_ref:.0%}\"\n",
    "    \n",
    "    # Ablation helpfulness\n",
    "    abl_help = df[(df['intervention'] == 'ablate') & (df['alpha'] == alpha) & (df['split'] == 'benign')]['is_helpful'].mean()\n",
    "    row['ablation_helpfulness'] = f\"{abl_help:.0%}\"\n",
    "    \n",
    "    table_data.append(row)\n",
    "\n",
    "comparison_table = pd.DataFrame(table_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PAPER TABLE FORMAT\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_table.to_string(index=False))\n",
    "\n",
    "# Save table\n",
    "comparison_table.to_csv(f'{results_dir}/intervention_comparison_table.csv', index=False)\n",
    "print(f\"\\n✅ Table saved to {results_dir}/intervention_comparison_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Paper Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Figure 1: Intervention Comparison (Refusal Rate)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "harm_df = df[df['split'] == 'harm_test']\n",
    "for intervention, label, color in [('add', 'Additive', '#3498db'), ('ablate', 'Ablation', '#2ecc71')]:\n",
    "    data = harm_df[harm_df['intervention'] == intervention].groupby('alpha')['is_refusal'].mean()\n",
    "    ax.plot(data.index, data.values, marker='o', label=label, color=color, linewidth=2, markersize=8)\n",
    "\n",
    "ax.set_xlabel('Alpha (Steering Strength)', fontsize=12)\n",
    "ax.set_ylabel('Refusal Rate on harm_test', fontsize=12)\n",
    "ax.set_title('Intervention Comparison: Additive vs Ablation - Mistral 7B', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{results_dir}/intervention_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Figure 1 saved: intervention_comparison.png\")\n",
    "\n",
    "# Figure 2: Safety-Helpfulness Tradeoff\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for intervention, label, color, marker in [\n",
    "    ('add', 'Additive', '#3498db', 'o'),\n",
    "    ('ablate', 'Ablation', '#2ecc71', 's')\n",
    "]:\n",
    "    points = []\n",
    "    for alpha in [1, 2, 4, 8]:\n",
    "        refusal = df[(df['intervention'] == intervention) & (df['alpha'] == alpha) & (df['split'] == 'harm_test')]['is_refusal'].mean()\n",
    "        helpfulness = df[(df['intervention'] == intervention) & (df['alpha'] == alpha) & (df['split'] == 'benign')]['is_helpful'].mean()\n",
    "        points.append((refusal, helpfulness))\n",
    "    \n",
    "    x, y = zip(*points)\n",
    "    ax.scatter(x, y, label=label, color=color, s=150, marker=marker, alpha=0.7)\n",
    "    ax.plot(x, y, color=color, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    # Add alpha labels\n",
    "    for (x_val, y_val), alpha in zip(points, [1, 2, 4, 8]):\n",
    "        ax.annotate(f'α={alpha}', (x_val, y_val), xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Refusal Rate on harm_test (Safety)', fontsize=12)\n",
    "ax.set_ylabel('Helpfulness on benign', fontsize=12)\n",
    "ax.set_title('Safety-Helpfulness Tradeoff - Mistral 7B', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xlim(0, 1.05)\n",
    "ax.set_ylim(0.85, 1.05)\n",
    "\n",
    "# Add ideal corner annotation\n",
    "ax.annotate('Ideal: High safety,\\nHigh helpfulness', xy=(1.0, 1.0), xytext=(0.7, 0.88),\n",
    "            arrowprops=dict(arrowstyle='->', color='gray', alpha=0.5),\n",
    "            fontsize=10, ha='center', color='gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{results_dir}/tradeoff_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Figure 2 saved: tradeoff_curve.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Distribution Shift (harm_train → harm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DISTRIBUTION SHIFT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare harm_train vs harm_test at alpha=8, ablation\n",
    "train_test_comparison = df[\n",
    "    (df['intervention'] == 'ablate') & \n",
    "    (df['alpha'] == 8) &\n",
    "    (df['split'].isin(['harm_train', 'harm_test']))\n",
    "].groupby('split')['is_refusal'].agg(['mean', 'std']).round(3)\n",
    "\n",
    "print(\"\\nRefusal rates (Ablation, α=8):\")\n",
    "print(train_test_comparison)\n",
    "\n",
    "gap = abs(train_test_comparison.loc['harm_train', 'mean'] - train_test_comparison.loc['harm_test', 'mean'])\n",
    "print(f\"\\nGeneralization gap: {gap:.1%}\")\n",
    "\n",
    "if gap < 0.05:\n",
    "    print(\"✅ EXCELLENT: Minimal generalization gap (<5%)\")\n",
    "elif gap < 0.10:\n",
    "    print(\"✅ GOOD: Small generalization gap (<10%)\")\n",
    "else:\n",
    "    print(\"⚠️  WARNING: Larger generalization gap (>10%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sample Completions\n",
    "\n",
    "Verify quality of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SAMPLE COMPLETIONS (α=8, harm_test)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "samples = df[\n",
    "    (df['alpha'] == 8) & \n",
    "    (df['split'] == 'harm_test') & \n",
    "    (df['intervention'] == 'ablate')\n",
    "].head(5)\n",
    "\n",
    "for idx, row in samples.iterrows():\n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"Prompt: {row['prompt'][:70]}...\")\n",
    "    print(f\"Completion: {row['completion'][:200]}...\")\n",
    "    print(f\"Refusal: {row['is_refusal']} (score: {row['refusal_score']:.2f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary & Download\n",
    "\n",
    "Package all results for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "print(\"=\"*80)\n",
    "print(\"EXPERIMENT SUMMARY - MISTRAL 7B\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. LAYER SENSITIVITY\")\n",
    "print(\"-\" * 40)\n",
    "layer_best = layer_summary[layer_summary['alpha'] == 4].nlargest(1, 'is_refusal')\n",
    "print(f\"Best layer: {int(layer_best['layer'].values[0])}\")\n",
    "print(f\"Performance: {layer_best['is_refusal'].values[0]:.1%} refusal at α=4\")\n",
    "\n",
    "print(\"\\n2. INTERVENTION COMPARISON (α=8)\")\n",
    "print(\"-\" * 40)\n",
    "add_8 = df[(df['intervention'] == 'add') & (df['alpha'] == 8) & (df['split'] == 'harm_test')]['is_refusal'].mean()\n",
    "abl_8 = df[(df['intervention'] == 'ablate') & (df['alpha'] == 8) & (df['split'] == 'harm_test')]['is_refusal'].mean()\n",
    "help_8 = df[(df['intervention'] == 'ablate') & (df['alpha'] == 8) & (df['split'] == 'benign')]['is_helpful'].mean()\n",
    "\n",
    "print(f\"Additive refusal: {add_8:.1%}\")\n",
    "print(f\"Ablation refusal: {abl_8:.1%}\")\n",
    "print(f\"Ablation helpfulness: {help_8:.1%}\")\n",
    "print(f\"Gap (ablation - additive): {(abl_8 - add_8):.1%}\")\n",
    "\n",
    "print(\"\\n3. DISTRIBUTION SHIFT\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Generalization gap: {gap:.1%}\")\n",
    "\n",
    "# Zip results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PACKAGING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "!zip -r mistral_full_results.zip \\\n",
    "  artifacts/runs/mistral_layer_sweep/ \\\n",
    "  artifacts/runs/mistral_intervention_comparison/\n",
    "\n",
    "from google.colab import files\n",
    "files.download('mistral_full_results.zip')\n",
    "\n",
    "print(\"\\n✅ All results downloaded!\")\n",
    "print(\"\\nFiles included:\")\n",
    "print(\"  - layer_comparison.png (Figure for Experiment 1)\")\n",
    "print(\"  - intervention_comparison.png (Figure for Experiment 2)\")\n",
    "print(\"  - tradeoff_curve.png (Safety-Helpfulness plot)\")\n",
    "print(\"  - intervention_comparison_table.csv (Paper table)\")\n",
    "print(\"  - all_results.parquet (Full data for both experiments)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
